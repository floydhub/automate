{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FloydHub SDK Demo\n",
    "\n",
    "This notebook shows how to use the Floyd SDK to automate your FloydHub workflow. You can do all the operations you perform on the cli programatically using the Python SDK. In fact the cli itself uses the sdk to communicate with the FloydHub server. Use pip to install the sdk.\n",
    "\n",
    "The best way to execute this notebook is to create a new directory and copy this notebook in to that directory. Then populate the current directory with some files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mYou are using pip version 18.0, however version 18.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Install sdk\n",
    "!pip install -q floyd-cli\n",
    "\n",
    "# Create some files for testing purposes\n",
    "!echo \"hello\" > ./hello.txt\n",
    "!echo \"print (\\\"Hello world\\\")\" > ./hello_world.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Authentication with username / password\n",
    "\n",
    "First step is to authenticate yourselves against the FloydHub server. You can use your username / password combo to get an access token from the server.\n",
    "\n",
    "The token is saved by the AuthConfigManager and automatically accessed in subsequent sdk calls. The path where this token is stored is `~/.floydconfig`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from floyd.client.auth import AuthClient\n",
    "from floyd.log import configure_logger\n",
    "from floyd.model.access_token import AccessToken\n",
    "from floyd.model.credentials import Credentials\n",
    "from floyd.manager.auth_config import AuthConfigManager\n",
    "\n",
    "# Initialize logger\n",
    "configure_logger(verbose=False)\n",
    "\n",
    "# Login using credentials (replace with your credentials)\n",
    "login_credentials = Credentials(username=\"your_username\", password=\"your_password\")\n",
    "access_code = AuthClient().login(login_credentials)\n",
    "user = AuthClient().get_user(access_code)\n",
    "access_token = AccessToken(username=user.username,\n",
    "                           token=access_code)\n",
    "\n",
    "# Auth token is stored and automatically used in subsequent sdk calls\n",
    "AuthConfigManager.set_access_token(access_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Authentication with API Key\n",
    "\n",
    "Alternatively, you can get an api key for your account at https://www.floydhub.com/settings/apikey. You can set the expiration of the key and use it for authentication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "AuthConfigManager.set_apikey(username=\"your_username\", apikey=\"apikey_from_floydhub\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "FloydHub manages data separately from code. You need to create a dataset directly from the [website](https://www.floydhub.com/datasets/create). Then use the dataset name in the section below to upload the contents of the current directory to FloydHub as a dataset. You will later mount this data into a job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compressing data...\n",
      "Making create request to server...\n",
      "Initializing upload...\n",
      "Uploading compressed data. Total upload size: 4.3KiB\n",
      "Removing compressed data...\n",
      "Upload finished.\n",
      "Waiting for server to unpack data.\n",
      "You can exit at any time and come back to check the status with:\n",
      "\tfloyd data upload -r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Waiting for unpack....\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NAME\n",
      "----------------------------\n",
      "floydlabs/datasets/test11/18\n"
     ]
    }
   ],
   "source": [
    "from floyd.client.data import DataClient\n",
    "from floyd.client.dataset import DatasetClient\n",
    "from floyd.manager.auth_config import AuthConfigManager\n",
    "from floyd.manager.data_config import DataConfig\n",
    "from floyd.cli.data_upload_utils import initialize_new_upload, complete_upload\n",
    "from floyd.cli.utils import get_namespace_from_name\n",
    "\n",
    "# Get access token from the stored config file\n",
    "# Or re-authenticate from the previous step\n",
    "access_token = AuthConfigManager.get_access_token()\n",
    "\n",
    "# Replace with your dataset name\n",
    "dataset_name = \"floydlabs/test11\"\n",
    "dataset = DatasetClient().get_by_name(dataset_name)\n",
    "\n",
    "namespace, name = get_namespace_from_name(dataset_name)\n",
    "data_config = DataConfig(name=name,\n",
    "                         namespace=namespace,\n",
    "                         family_id=dataset.id)\n",
    "\n",
    "# This is the actual upload step\n",
    "initialize_new_upload(data_config, access_token, \"new upload\")\n",
    "complete_upload(data_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from floyd.manager.data_config import DataConfigManager\n",
    "from floyd.cli.utils import normalize_data_name\n",
    "\n",
    "# Get the uploaded data name\n",
    "data_config = DataConfigManager.get_config()\n",
    "data_name = normalize_data_name(data_config.data_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Job\n",
    "\n",
    "You can kick off a training job, monitor it and download the output all using the sdk. The next section shows how to run a job under a specific project. Create the project from the FloydHub [website](https://www.floydhub.com/projects/create) and use the project name in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from floyd.client.project import ProjectClient\n",
    "from floyd.manager.experiment_config import ExperimentConfigManager\n",
    "from floyd.manager.floyd_ignore import FloydIgnoreManager\n",
    "from floyd.model.experiment_config import ExperimentConfig\n",
    "from floyd.cli.utils import get_namespace_from_name\n",
    "\n",
    "# Replace with your project name\n",
    "project_name = \"floydlabs/private-proj\"\n",
    "project = ProjectClient().get_by_name(project_name)\n",
    "\n",
    "namespace, name = get_namespace_from_name(project_name)\n",
    "experiment_config = ExperimentConfig(name=name,\n",
    "                                     namespace=namespace,\n",
    "                                     family_id=project.id)\n",
    "ExperimentConfigManager.set_config(experiment_config)\n",
    "FloydIgnoreManager.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mounting Data\n",
    "\n",
    "You can mount any data on FloydHub (that you have access to) in to your job at the path you specify. In this case we are mounting the dataset we created above and mounting it at `/training` path. You also need to specify the floydhub instance type and the [environment](https://docs.floydhub.com/guides/environments/) you want to use.\n",
    "\n",
    "Running a job is currently two step process - you first need to upload the code and then run the experiment (or job)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating project run. Total upload size: 29.3KiB\n",
      "Syncing code ...\n"
     ]
    }
   ],
   "source": [
    "from floyd.client.experiment import ExperimentClient\n",
    "from floyd.client.module import ModuleClient\n",
    "from floyd.constants import INSTANCE_ARCH_MAP\n",
    "from floyd.model.experiment import ExperimentRequest\n",
    "from floyd.model.module import Module\n",
    "\n",
    "# Run a job\n",
    "# Get the data mount id (data_name comes from the previous step)\n",
    "data_obj = DataClient().get(normalize_data_name(data_name))\n",
    "data_ids = [\"{}:{}\".format(data_obj.id, \"/training\")]\n",
    "\n",
    "# Define the data mount point for data\n",
    "module_inputs = {\n",
    "    \"name\": \"/training\",\n",
    "    \"type\": \"dir\" # Always use dir here\n",
    "}\n",
    "    \n",
    "# First create a module and then use it in the experiment create step\n",
    "\n",
    "experiment_name = project_name\n",
    "instance_type = \"c1\" # You can use c1 for cpu, c2 for cpu2, g1 for gpu and g2 for gpu2\n",
    "project_id = project.id\n",
    "\n",
    "# Get env value\n",
    "arch = INSTANCE_ARCH_MAP[instance_type]\n",
    "env = \"tensorflow-1.5\"  # Choose env that you need\n",
    "\n",
    "module = Module(name=experiment_name,\n",
    "                description='foo',\n",
    "                command=\"ls /training\",\n",
    "                mode='command',\n",
    "                family_id=project_id,\n",
    "                inputs=module_inputs,\n",
    "                env=env,\n",
    "                arch=arch)\n",
    "\n",
    "module_id = ModuleClient().create(module)\n",
    "    \n",
    "experiment_request = ExperimentRequest(name=experiment_name,\n",
    "                                       description='foo',\n",
    "                                       full_command='ls /training',\n",
    "                                       module_id=module_id,\n",
    "                                       env=env,\n",
    "                                       data_ids=data_ids,\n",
    "                                       family_id=project_id,\n",
    "                                       instance_type=instance_type)\n",
    "expt_info = ExperimentClient().create(experiment_request)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tracking an experiment\n",
    "\n",
    "You can track an experiment periodically and wait for it to finish. You can also setup a [notification webhook](https://docs.floydhub.com/guides/notifications/) and get notified when jobs finish. You can also programatically download the output of your training job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success\n"
     ]
    }
   ],
   "source": [
    "from floyd.client.experiment import ExperimentClient\n",
    "from floyd.client.resource import ResourceClient\n",
    "\n",
    "# Track experiment\n",
    "job_id = expt_info['id']\n",
    "experiment = ExperimentClient().get(job_id)\n",
    "print(experiment.state)\n",
    "\n",
    "# Stop running job (works only if the job is queued or running)\n",
    "# ExperimentClient().stop(job_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-01-15 10:59:43,547 INFO - Preparing to run TaskInstance <TaskInstance: floydlabs/projects/private-proj/95 (id: MojAv2Wf9kGjENAfqhDEUV)\n",
      "2019-01-15 10:59:43,573 INFO - Starting attempt 1\n",
      "2019-01-15 10:59:43,590 INFO - Downloading and setting up data sources\n",
      "2019-01-15 10:59:43,602 INFO - Downloading and mounting training. ETA: 2 seconds\n",
      "2019-01-15 10:59:43,990 INFO - Using Docker image: floydhub/tensorflow:1.5.0-py3_aws.35\n",
      "2019-01-15 10:59:44,121 INFO - Starting container...\n",
      "2019-01-15 10:59:44,329 INFO - \n",
      "################################################################################\n",
      "\n",
      "2019-01-15 10:59:44,330 INFO - Run Output:\n",
      "2019-01-15 10:59:44,344 INFO - Starting services.\n",
      "2019-01-15 10:59:44,493 INFO - demo\n",
      "2019-01-15 10:59:44,493 INFO - floydhub_sdk_demo.ipynb\n",
      "2019-01-15 10:59:44,493 INFO - hello.txt\n",
      "2019-01-15 10:59:44,493 INFO - hello_world.py\n",
      "2019-01-15 10:59:44,545 INFO - \n",
      "################################################################################\n",
      "\n",
      "2019-01-15 10:59:44,546 INFO - Waiting for container to complete...\n",
      "2019-01-15 10:59:44,708 INFO - Persisting outputs...\n",
      "2019-01-15 10:59:45,002 INFO - Creating data module for output...\n",
      "2019-01-15 10:59:45,076 INFO - Data module created for output.\n",
      "2019-01-15 10:59:45,076 INFO - Persisting data in home...\n",
      "2019-01-15 10:59:45,341 INFO - Home data persisted.\n",
      "2019-01-15 10:59:45,341 INFO - [success] Finished execution\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get logs\n",
    "log_resource_id = experiment.instance_log_id\n",
    "logs = ResourceClient().get_content(log_resource_id)\n",
    "print(logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading the tar file to the current directory ...\n",
      "Untarring the contents of the file ...\n",
      "Cleaning up the tar file ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'output.tar'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download an output model file\n",
    "output_id = experiment.output_id\n",
    "data_url = \"https://www.floydhub.com/api/v1/resources/{}?content=true&download=true\".format(output_id)\n",
    "DataClient().download_tar(url=data_url,\n",
    "                          untar=True,\n",
    "                          delete_after_untar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'can_edit': True,\n",
       " 'canvas': {'nodes': {'node1': {'connections': {'yRXw8MaMiTPqsZVr5RRR7N_data_node1_training': {'id': 'yRXw8MaMiTPqsZVr5RRR7N_data_node1_training',\n",
       "      'sourceEndpointId': 'yRXw8MaMiTPqsZVr5RRR7N_data',\n",
       "      'sourceEndpointName': 'data',\n",
       "      'sourceId': 'yRXw8MaMiTPqsZVr5RRR7N',\n",
       "      'targetEndpointId': 'node1_training',\n",
       "      'targetEndpointName': 'training',\n",
       "      'targetId': 'node1'}},\n",
       "    'container': 'docker:floydhub/tensorflow:1.5.0-py3_aws.35',\n",
       "    'contentId': 'eikisomXhm4Mr7tem9BHvW',\n",
       "    'id': 'node1',\n",
       "    'inputs': [{'name': 'training', 'type': 'dir'}],\n",
       "    'instanceType': 'c1',\n",
       "    'instanceTypeInherited': True,\n",
       "    'label': 'floydlabs/projects/private-proj/95',\n",
       "    'outputs': [{'id': 'Hiyxsb8UKPPQTFYBHPzk4G',\n",
       "      'name': 'output',\n",
       "      'type': 'dir'}],\n",
       "    'params': [],\n",
       "    'state': 'success',\n",
       "    'style': {'left': '132px', 'top': '284px'},\n",
       "    'taskInstanceId': 'MojAv2Wf9kGjENAfqhDEUV',\n",
       "    'type': 'module_node',\n",
       "    'version': '95'},\n",
       "   'yRXw8MaMiTPqsZVr5RRR7N': {'connections': {},\n",
       "    'container': 'docker:ubuntu:latest',\n",
       "    'contentId': 'yRXw8MaMiTPqsZVr5RRR7N',\n",
       "    'id': 'yRXw8MaMiTPqsZVr5RRR7N',\n",
       "    'inputs': [],\n",
       "    'instanceType': 'c1',\n",
       "    'instanceTypeInherited': True,\n",
       "    'label': 'floydlabs/datasets/test11/18',\n",
       "    'outputs': [{'id': 'iFmVoZrzheUuZKaPZ9mYgG',\n",
       "      'name': 'data',\n",
       "      'type': 'dir'}],\n",
       "    'params': [],\n",
       "    'state': 'success',\n",
       "    'style': {'left': '0px'},\n",
       "    'taskInstanceId': 'sKi9b3832TH7TzT6NCowo2',\n",
       "    'type': 'data_node',\n",
       "    'version': '18'}}},\n",
       " 'command': 'ls /training',\n",
       " 'created': '2019-01-15T18:59:40.928487+00:00',\n",
       " 'default_args': [],\n",
       " 'description': 'foo',\n",
       " 'dt_ended': 1547578786,\n",
       " 'dt_started': 1547578783,\n",
       " 'duration': 3.313481,\n",
       " 'ended': '2019-01-15T18:59:46.378750+00:00',\n",
       " 'environment': 'docker:floydhub/tensorflow:1.5.0-py3_aws.35',\n",
       " 'family_id': 'LqYoKnwX5SoP5qxGz3LQzZ',\n",
       " 'full_command': \"floyd run --cpu --env tensorflow-1.5 --data floydlabs/datasets/test11/18:/training --message foo 'ls /training'\",\n",
       " 'home_resource': {'data_type': 'dir',\n",
       "  'date_finalized': '2019-01-15T18:59:45.316833+00:00',\n",
       "  'date_last_updated': '2019-01-15T18:59:45.074297+00:00',\n",
       "  'id': 'MChyvgRJ6qS68g42h4Kp93',\n",
       "  'owner': 'team_agVtsExAUShLspQhUCEYTE',\n",
       "  'resource_type': 'S3Data',\n",
       "  'size': '53.0 KB',\n",
       "  'size_bytes': 54272,\n",
       "  'state': 'valid',\n",
       "  'uri': 's3://3c2a53e0303d944c3f427073490e5dbc1badfc1f'},\n",
       " 'id': 'ZEByWbnNGEnRbBdwagpePQ',\n",
       " 'instanceLogId': 'xLvBPKMfjXVrjkXSraemsg',\n",
       " 'instanceOutputId': 'Hiyxsb8UKPPQTFYBHPzk4G',\n",
       " 'instanceType': 'c1',\n",
       " 'instance_home_resource_id': 'MChyvgRJ6qS68g42h4Kp93',\n",
       " 'lastUpdated': '2019-01-15T18:59:46.378750+00:00',\n",
       " 'latest_metrics': {},\n",
       " 'logId': 'aaRh4EWYF9A8AWqgksGsN4',\n",
       " 'mode': 'cli',\n",
       " 'name': 'floydlabs/projects/private-proj/95',\n",
       " 'namespace': 'floydlabs',\n",
       " 'output_resource': {'data_type': 'dir',\n",
       "  'date_finalized': '2019-01-15T18:59:44.960127+00:00',\n",
       "  'date_last_updated': '2019-01-15T18:59:44.958662+00:00',\n",
       "  'id': 'Hiyxsb8UKPPQTFYBHPzk4G',\n",
       "  'owner': 'team_agVtsExAUShLspQhUCEYTE',\n",
       "  'resource_type': 'S3Data',\n",
       "  'size': '5.0 KB',\n",
       "  'size_bytes': 5120,\n",
       "  'state': 'valid',\n",
       "  'uri': 's3://c18459a85a6981afa05246793f333c00de47c596'},\n",
       " 'params': [],\n",
       " 'predecessor_id': None,\n",
       " 'projectName': 'private-proj',\n",
       " 'push_channel': 'presence-job=ZEByWbnNGEnRbBdwagpePQ',\n",
       " 'started': '2019-01-15T18:59:43.065269+00:00',\n",
       " 'state': 'success',\n",
       " 'submitter': {'email': 'a2u6k9l8h3a7n6z5@floydhub.slack.com',\n",
       "  'kind': 'person',\n",
       "  'username': 'pinkfloyd'},\n",
       " 'tags': None,\n",
       " 'timeout_seconds': 604800,\n",
       " 'version': '95',\n",
       " 'visibility': 'private'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Get detailed info about the experiment by directly parsing the job info json.\n",
    "## Note: Some of these fields are for internal use and can change without warning.\n",
    "\n",
    "from floyd.client.experiment import ExperimentClient\n",
    "\n",
    "ExperimentClient().request(\"GET\", \"/experiments/\" + experiment.id).json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support\n",
    "\n",
    "This sdk is in beta. If you have any questions or are interested in adopting this for your workflow, please contact us at support@floydhub.com. We are happy to support you and work with you in automating your training."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
